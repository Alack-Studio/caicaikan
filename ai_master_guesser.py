import streamlit as st
from openai import OpenAI
import random

# 1. èµ›åšæ·±å¤œ UIï¼šä¿ç•™ç²¾è‡´å‘å…‰ï¼Œå»é™¤å†—ä½™æè¿°
st.set_page_config(page_title="AI çŒœçŒœçœ‹", layout="centered")

# åˆå§‹åŒ–çŠ¶æ€
states = {"msgs":[], "role":"AI çŒœ", "over":False, "model":"gemini-2.5-flash-lite", "count":0, "pending":None}
for k, v in states.items():
    if k not in st.session_state: st.session_state[k] = v

with st.sidebar:
    if st.button("ğŸ”„ é‡ç½®æ‰€æœ‰è¿›åº¦", use_container_width=True):
        for k in ["msgs", "over", "count", "pending"]: 
            st.session_state[k] = [] if k=="msgs" else (0 if k=="count" else (None if k=="pending" else False))
        st.rerun()

# èµ›åšè“å…‰å˜é‡
bg, txt, glow_c, c_bg = "#121212", "#D1D1D1", "0, 210, 255", "rgba(255,255,255,0.03)"

st.markdown(f"""
    <style>
    @keyframes breathe {{
        0% {{ box-shadow: 0 0 4px rgba({glow_c}, 0.15); border-color: rgba({glow_c}, 0.3); }}
        50% {{ box-shadow: 0 0 10px rgba({glow_c}, 0.4); border-color: rgba({glow_c}, 0.5); }}
        100% {{ box-shadow: 0 0 4px rgba({glow_c}, 0.15); border-color: rgba({glow_c}, 0.3); }}
    }}
    .stApp {{ background-color: {bg}; color: {txt} !important; font-family: -apple-system, sans-serif; }}
    .stApp p, .stApp h1, .stApp h3 {{ color: {txt} !important; }}
    
    /* æç®€æ°”æ³¡ */
    .stChatMessage {{ 
        background-color: {c_bg} !important; border-radius: 10px; padding: 10px; 
        border: 0.6px solid rgba({glow_c}, 0.3); animation: breathe 4s infinite ease-in-out; margin-bottom: 8px; 
    }}
    .stChatMessage p {{ font-size: 1.05rem !important; line-height: 1.6; color: {txt} !important; }}
    
    /* å·¦å¯¹é½å¿«æ·æ°”æ³¡ */
    div.stButton > button {{
        border-radius: 20px; height: 2.1em; font-size: 0.85rem !important;
        padding: 0 12px; background-color: transparent; 
        color: {txt} !important; border: 0.8px solid rgba({glow_c}, 0.3);
        transition: 0.3s all;
    }}
    div.stButton > button:hover {{ border-color: #00D2FF; color: #00D2FF !important; }}
    
    /* ç»“ç®—å±•ç¤º */
    .rank-badge {{
        text-align: center; padding: 15px; border-radius: 12px;
        border: 1px solid #00D2FF; background: rgba(0, 210, 255, 0.03);
        margin: 20px 0;
    }}
    header {{visibility: hidden;}}
    .stSpinner p {{ font-size: 0.9rem !important; color: #00D2FF; opacity: 0.7; }}
    </style>
    """, unsafe_allow_html=True)

st.title("ğŸ•µï¸ AI çŒœçŒœçœ‹")

# 2. æ ¸å¿ƒ API ä¸ çº¯å‡€é€»è¾‘
client = OpenAI(api_key=st.secrets["API_KEY"], base_url="https://api.gptsapi.net/v1")

def ask_ai(inp=None):
    if inp: 
        st.session_state.msgs.append({"role": "user", "content": inp})
        st.session_state.count += 1
    
    with st.spinner("å¤„ç†ä¸­..."):
        if st.session_state.role == "AI çŒœ":
            sys = "ä½ æ˜¯ä¸€ä¸ªçŒœè°œåŠ©æ‰‹ã€‚æˆ‘å¿ƒé‡Œæƒ³ä¸€ä¸ªè‘—åäººç‰©ï¼Œä½ é€šè¿‡æ˜¯éé¢˜æ¥çŒœã€‚ä¸¥ç¦å‰5è½®è¯¢é—®æ€§åˆ«æˆ–å›½ç±ã€‚ç¡®å®šåä»¥'ç­”æ¡ˆæ˜¯ï¼š[äººå]'å¼€å¤´ã€‚"
        else:
            # â€œæˆ‘çŒœâ€æ¨¡å¼ï¼šçº¯å‡€å¼•å¯¼é€»è¾‘
            sys = ("ä½ å·²é€‰å®šä¸€ä¸ªä¸–ç•Œè‘—åäººç‰©ã€‚ç”¨æˆ·é—®æ˜¯éé¢˜ï¼Œä½ ä»…ç­”'æ˜¯/å¦/æ¨¡ç³Š'å¹¶é™„å¸¦ç®€çŸ­æç¤ºã€‚"
                   "ä¸¥ç¦è¿›è¡Œä»»ä½•è§’è‰²æ‰®æ¼”ã€‚ç¬¬ä¸€æ¡æ¶ˆæ¯è¯·ç›´æ¥ç»™å‡ºæ¬¢è¿è¯­å’Œæå…¶æ¨¡ç³Šçš„åˆ†ç±»æç¤ºã€‚")
            
        try:
            res = client.chat.completions.create(model=st.session_state.model, messages=[{"role":"system","content":sys}]+st.session_state.msgs, temperature=0.7)
            reply = res.choices[0].message.content
            st.session_state.msgs.append({"role":"assistant", "content":reply})
            if any(x in reply for x in ["ç­”æ¡ˆæ˜¯", "è·èƒœ", "æ­å–œ", "æ­æ™“ç­”æ¡ˆ"]):
                st.session_state.over = True
        except Exception as e: st.error(f"ğŸ“¡ API å¼‚å¸¸: {str(e)}")

if st.session_state.pending:
    ans = st.session_state.pending
    st.session_state.pending = None
    ask_ai(ans); st.rerun()

# 3. æ¸¸æˆæ¸²æŸ“
if not st.session_state.msgs:
    st.session_state.role = st.radio("ğŸ­ æ¨¡å¼ï¼š", ["AI çŒœ (å®ƒé—®æˆ‘ç­”)", "æˆ‘çŒœ (æˆ‘é—®å®ƒç­”)"], horizontal=True)
    st.session_state.model = st.radio("ğŸ”® å¯¹è±¡", ["gemini-2.5-flash-lite", "gemini-2.5-pro", "gemini-3-pro-preview"], captions=["å¿«é€Ÿ", "æ·±åº¦", "ç»ˆæ"])
    if st.button("ğŸš€ å¼€å§‹æ¸¸æˆ", use_container_width=True, type="primary"):
        ask_ai(); st.rerun()
else:
    for m in st.session_state.msgs:
        with st.chat_message(m["role"], avatar="ğŸ•µï¸" if m["role"]=="assistant" else "ğŸ‘¤"):
            st.markdown(m["content"])

    if not st.session_state.over:
        if st.session_state.role == "AI çŒœ":
            c1, c2, c3 = st.columns(3)
            if c1.button("âœ… æ˜¯", use_container_width=True): st.session_state.pending = "æ˜¯çš„"; st.rerun()
            if c2.button("âŒ å¦", use_container_width=True): st.session_state.pending = "ä¸æ˜¯"; st.rerun()
            if c3.button("â” æ¨¡ç³Š", use_container_width=True): st.session_state.pending = "ä¸ç¡®å®š"; st.rerun()
        else:
            # å¿«æ·åŠŸèƒ½å·¦å¯¹é½
            qc1, qc2, qc3, qc4 = st.columns([0.18, 0.22, 0.22, 0.38])
            with qc1: 
                if st.button("ğŸ’¡ æç¤º"): st.session_state.pending = "è¯·å¤šç»™ç‚¹æç¤ºã€‚"; st.rerun()
            with qc2: 
                if st.button("ğŸ™… çŒœä¸åˆ°"): st.session_state.pending = "æˆ‘æƒ³ä¸å‡ºæ¥äº†ï¼Œè¯·æ­æ™“ç­”æ¡ˆã€‚"; st.rerun()
            with qc3: 
                if st.button("ğŸ”„ æ¢ä¸€ä¸ª"): 
                    st.session_state.msgs, st.session_state.count = [], 0
                    ask_ai(); st.rerun()
            q = st.chat_input("è¾“å…¥ä½ çš„é—®é¢˜...")
            if q: ask_ai(q); st.rerun()
    else:
        st.balloons()
        st.markdown(f'<div class="rank-badge"><h3>ğŸ¯ æ¸¸æˆç»“æŸ</h3><p>æ€»è®¡æ¶ˆè€—æé—®: {st.session_state.count} æ¬¡</p></div>', unsafe_allow_html=True)
        if st.button("ğŸ® å†ç©ä¸€å±€", use_container_width=True, type="primary"):
            st.session_state.msgs, st.session_state.over, st.session_state.count = [], False, 0
            st.rerun()
